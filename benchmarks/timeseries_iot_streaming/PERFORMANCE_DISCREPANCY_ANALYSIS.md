# PAX INSERT Performance Discrepancy - Critical Finding

**Date**: October 30, 2025
**Benchmark**: timeseries_iot_streaming - Phase 1
**Cloudberry Version**: 3.0.0-devel+dev.2154.gda0b9d4fe08

---

## Executive Summary

üî¥ **CRITICAL FINDING**: PAX INSERT performance **does NOT match** official Apache Cloudberry documentation claims.

| Source | Claim | Actual Result | Gap |
|--------|-------|---------------|-----|
| **Official Docs** | "PAX has the same writer performance as AO tables" | PAX: 80.4% of AO speed | **-19.6%** |
| **Marketing** | "Batch write performance similar to row-based storage" | PAX: 249K rows/sec vs AO: 310K rows/sec | **-61K rows/sec** |
| **User Expectation** | "Achieve the ingestion speed of AO tables" | PAX INSERT speed closer to AOCO than AO | ‚ùå **Failed** |

---

## Official Documentation Claims

### Source 1: Apache Cloudberry Documentation (2025)
> "PAX is a hybrid row-column storage for Cloudberry Database, **having the same writer performance as AO tables** and the same read performance as AOCS tables."

**URL**: https://cloudberry.apache.org/docs/operate-with-data/pax-table-format/

### Source 2: Apache Cloudberry Medium Article (Sep 2025)
> "PAX offers **batch write performance similar to row-based storage** and read performance like column-based storage."

**URL**: https://medium.com/@jianlirong/apache-cloudberry-2-0-0-the-first-apache-release-embracing-community-driven-innovation-e530d8cb4d3f

### Source 3: User Feedback
> "Another very important design goal of PAX tables is to **achieve the ingestion speed of AO tables** and the query speed of AOCS tables."

---

## Actual Benchmark Results

### Phase 1: Streaming INSERT (No Indexes)

**Dataset**: 39.21M rows, 500 batches, 24-hour realistic traffic pattern
**Configuration**: 3 bloom filter columns, 9 minmax columns, Z-order clustering
**Runtime**: 597 seconds total

| Variant | INSERT Throughput | % of AO | % of AOCO | Assessment |
|---------|-------------------|---------|-----------|------------|
| **AO** (baseline) | **310,363 rows/sec** | 100% | 105.1% | üèÜ Fastest writes |
| **AOCO** (baseline) | **295,371 rows/sec** | 95.2% | 100% | ‚úÖ Competitive |
| **PAX-no-cluster** | **252,223 rows/sec** | 81.3% | 85.4% | ‚ö†Ô∏è 15% slower than AOCO |
| **PAX (clustered)** | **249,463 rows/sec** | **80.4%** | 84.4% | ‚ùå **20% slower than AO** |

**Key Finding**: PAX INSERT speed is **closer to AOCO (15% gap) than to AO (20% gap)**.

---

## Gap Analysis

### 1. Performance vs AO (Row-Oriented Baseline)

**Gap**: 60,900 rows/sec (19.6% slower)

**Implications**:
- **100K rows/sec workload**: PAX has 2.49x headroom ‚úÖ (sufficient)
- **200K rows/sec workload**: PAX has 1.25x headroom ‚ö†Ô∏è (marginal)
- **250K rows/sec workload**: PAX has 0.998x headroom ‚ùå (cannot keep up)

**Conclusion**: PAX does **NOT** achieve "AO-level write speed" as documented.

### 2. Performance vs AOCO (Column-Oriented Baseline)

**Gap**: 43,148 rows/sec (14.6% slower)

**This is surprising** because:
- AOCO is traditionally the **slowest** for writes (columnar encoding overhead)
- PAX claims to optimize write path with row-oriented micro-partitions
- 15% slower than AOCO suggests PAX has **additional overhead** beyond columnar encoding

---

## Hypothesis: Root Causes of Overhead

### Hypothesis 1: Bloom Filter Building During INSERT (PRIMARY SUSPECT)

**Evidence**:
1. PAX configuration has **3 bloom filter columns** (`call_id`, `caller_number`, `callee_number`)
2. Bloom filters are built **per micro-partition file** during INSERT
3. Each batch triggers bloom filter construction for high-cardinality columns

**Expected Impact**:
- **Per-batch overhead**: ~20-30ms for bloom filter building
- **500 batches**: 10-15 seconds total overhead
- **Percentage overhead**: ~2-3% of total INSERT time

**Verdict**: Bloom filters likely contribute **2-5% of the 20% gap**.

### Hypothesis 2: MinMax Statistics Calculation

**Evidence**:
1. PAX configuration has **9 minmax columns**
2. Statistics are calculated during INSERT and stored in file metadata
3. Lightweight compared to bloom filters, but non-zero cost

**Expected Impact**: ~1-2% of total INSERT time

**Verdict**: MinMax statistics contribute **1-2% of the 20% gap**.

### Hypothesis 3: Columnar Encoding Overhead

**Evidence**:
1. PAX uses columnar storage format (PORC)
2. Similar to AOCO's columnar encoding
3. PAX is 15% slower than AOCO, suggesting **additional** overhead

**Expected Impact**:
- AOCO columnar encoding: ~5% slower than AO
- PAX columnar encoding: Similar to AOCO
- **PAX is slower than AOCO**: Suggests PAX has inefficiency

**Verdict**: Columnar encoding explains **5% of the 20% gap**, but PAX should match AOCO, not be slower.

### Hypothesis 4: Micro-Partition Metadata Overhead

**Evidence**:
1. PAX writes rich protobuf metadata per file
2. Includes statistics, bloom filters, encoding info
3. Stored in `pg_ext_aux.pg_pax_blocks_<oid>` auxiliary table

**Expected Impact**:
- Per-file metadata write: ~5-10ms
- ~8 files created for 39.21M rows
- Total overhead: ~40-80ms (negligible)

**Verdict**: Metadata overhead contributes **<1% of the 20% gap**.

### Hypothesis 5: Z-Order Clustering During INSERT?

**Evidence**:
- PAX-clustered: 249,463 rows/sec
- PAX-no-cluster: 252,223 rows/sec
- **Difference**: 2,760 rows/sec (1.1%)

**Verdict**: Z-order clustering does **NOT** slow down INSERT (clustering happens during CLUSTER command, not INSERT).

---

## Unaccounted Overhead: 10-12%

**Known overhead sources**:
- Bloom filters: ~2-5%
- MinMax statistics: ~1-2%
- Columnar encoding: ~5% (should match AOCO)
- Metadata: ~<1%
- **Total explained**: ~8-13%

**Total measured gap**: 19.6% (vs AO), 14.6% (vs AOCO)

**Unaccounted overhead**: **10-12%** (vs AOCO) - **THIS IS THE PROBLEM**

### Why Is PAX Slower Than AOCO?

PAX should match or exceed AOCO write speed because:
1. **Same columnar encoding** (PORC vs AOCO columnar)
2. **Optimized write path** (micro-partitions, batch writes)
3. **No indexes** (Phase 1 test, no index maintenance overhead)

**Hypothesis**: PAX has an **inefficiency in the write path** compared to AOCO.

**Possible causes**:
1. **Bloom filter overhead underestimated**: 3 bloom filters may cost more than 2-5%
2. **Auxiliary table writes**: Metadata writes to `pg_pax_blocks_<oid>` may be slow
3. **Protobuf serialization**: File metadata serialization overhead
4. **File creation overhead**: PAX creates multiple files per batch (8 files for 39M rows)
5. **WAL overhead**: PAX custom WAL records (rmgr: pax) may be heavier than AOCO

---

## Production Impact Assessment

### Customer Scenario: 100K rows/sec Continuous Batch Loading

**Required throughput**: 100,000 rows/sec
**PAX achieves**: 249,463 rows/sec
**Headroom**: **2.49x** ‚úÖ

**Verdict**: PAX **CAN** handle moderate streaming workloads, but with **60% less safety margin** than AO.

### When PAX INSERT Speed Becomes a Blocker

| Workload Intensity | AO Headroom | AOCO Headroom | PAX Headroom | Recommendation |
|-------------------|-------------|---------------|--------------|----------------|
| **100K rows/sec** | 3.1x ‚úÖ | 2.95x ‚úÖ | 2.49x ‚úÖ | All viable |
| **150K rows/sec** | 2.07x ‚úÖ | 1.97x ‚úÖ | 1.66x ‚úÖ | PAX marginal |
| **200K rows/sec** | 1.55x ‚úÖ | 1.48x ‚úÖ | 1.25x ‚ö†Ô∏è | PAX risky |
| **250K rows/sec** | 1.24x ‚úÖ | 1.18x ‚úÖ | **0.998x ‚ùå** | PAX fails |
| **300K rows/sec** | 1.03x ‚ö†Ô∏è | **0.98x ‚ùå** | **0.831x ‚ùå** | Only AO |

**Critical threshold**: PAX cannot sustain **>250K rows/sec** continuous batch loading.

---

## Recommendations

### 1. For Documentation Team

**Current claim** (INCORRECT):
> "PAX has the same writer performance as AO tables"

**Recommended revision**:
> "PAX achieves **80-85% of AO write performance** while maintaining AOCO-level query performance. For workloads requiring sustained writes above 250K rows/sec, consider AO tables."

### 2. For Benchmark Users

**Before recommending PAX for streaming workloads**:
1. ‚úÖ Measure actual INSERT throughput in your environment
2. ‚úÖ Calculate headroom: `(PAX_throughput / required_throughput) > 1.5x`
3. ‚úÖ Run Phase 2 benchmark to validate query speedup justifies write penalty
4. ‚ö†Ô∏è Do NOT assume "AO-level write speed" based on documentation

### 3. For PAX Development Team

**Investigate why PAX is 15% slower than AOCO**:
1. Profile bloom filter construction overhead (expected: 2-5%, actual: unknown)
2. Measure auxiliary table write latency (`pg_pax_blocks_<oid>` HEAP inserts)
3. Compare PAX WAL overhead vs AOCO WAL overhead
4. Benchmark PORC encoding vs AOCO encoding (should be equivalent)
5. Identify if file creation overhead is significant (8 files vs 1 file per batch?)

**Goal**: Reduce PAX INSERT overhead from **20% slower than AO** to **5-10% slower** (competitive with AOCO).

### 4. For Customers Facing the "AO vs AOCO Dilemma"

**Original dilemma**:
- AO: Fast writes ‚úÖ, slow queries ‚ùå
- AOCO: Slow writes ‚ùå, fast queries ‚úÖ

**PAX reality** (based on benchmark):
- PAX writes: **85% of AOCO speed** (not "AO-level")
- PAX queries: Unknown (Phase 2 will validate)

**Decision framework**:

| Workload Pattern | Recommendation | Justification |
|------------------|----------------|---------------|
| **<100K rows/sec** | ‚úÖ PAX | 2.49x headroom, query benefits expected |
| **100-200K rows/sec** | ‚ö†Ô∏è PAX (test first) | 1.25-2.49x headroom, marginal safety |
| **200-250K rows/sec** | ‚ö†Ô∏è AO (unless PAX queries justify) | 0.998-1.25x headroom, risky |
| **>250K rows/sec** | ‚ùå AO only | PAX cannot sustain |

**Critical**: Run Phase 2 benchmark to validate if PAX query speedup justifies 15-20% write penalty.

---

## Next Steps

### Immediate (Phase 2)

**Goal**: Validate if PAX query performance justifies the 20% write penalty

1. ‚úÖ Run Phase 2 benchmark (INSERT with indexes)
2. ‚úÖ Measure query performance vs AOCO
3. ‚úÖ Calculate ROI: Does PAX query speedup (expected: 25-50% faster) offset write penalty (20% slower)?

### Short-term (Performance Investigation)

**Goal**: Identify and reduce PAX INSERT overhead

1. ‚ùå Create PAX variant WITHOUT bloom filters (test if bloom filters cause 10-15% overhead)
2. ‚ùå Profile auxiliary table write latency
3. ‚ùå Compare PAX WAL vs AOCO WAL overhead
4. ‚ùå Measure file creation overhead (8 files vs 1 file)

### Long-term (Documentation & Development)

**Goal**: Align documentation with reality, improve PAX write performance

1. ‚ùå Update Apache Cloudberry documentation (remove "same writer performance as AO" claim)
2. ‚ùå File GitHub issue for PAX dev team (investigate 15% AOCO gap)
3. ‚ùå Add write performance benchmarks to official PAX documentation
4. ‚ùå Create production deployment guide with INSERT throughput thresholds

---

## Conclusion

**PAX does NOT achieve "AO-level write speed"** as claimed in official documentation.

**Actual performance**:
- **20% slower than AO** (310K vs 249K rows/sec)
- **15% slower than AOCO** (295K vs 249K rows/sec) ‚Üê **Most concerning**
- **Viable for <200K rows/sec** streaming workloads
- **Cannot sustain >250K rows/sec** continuous batch loading

**Critical question for Phase 2**:
> Does PAX query performance improvement (expected: 25-50% faster than AOCO) justify the 15-20% write penalty?

**Without Phase 2 validation, we cannot recommend PAX for the "AO vs AOCO dilemma"** because we've only proven PAX is slower at writes, not faster at queries.

---

**Next**: Run Phase 2 (INSERT with indexes) to complete the analysis.
